# SPIR – Intelligent Planning Toolkit (HackMTY 2025)

SPIR (Smart Planning Intelligent Resources) is the data & backend foundation of our HackMTY 2025 solution for gategroup.  
This repository delivers:

* an end‑to‑end notebook that trains a <2 % MAPE consumption model,  
* reproducible artifacts (.pkl) ready for serving, and  
* a FastAPI backend that exposes staffing, demand, and financial impact simulators.

> **Status:** Frontend work is tracked separately; this branch contains the complete data + backend stack so judges can reproduce results and interact with the APIs directly.

---

## Repository Layout

```
backend/
  app/
    financial.py          # financial impact engine (model + metrics)
    main.py               # FastAPI entrypoint
    models.py             # Pydantic request/response schemas
docs/
  images/banner.png
notebooks/
  consumption_prediction.ipynb
data/
  external/               # place the raw Excel datasets here (see below)
scripts/
  ...                     # optional helper scripts (if any)
```

Artifacts generated by the notebook (e.g. `backend/models/consumption_prediction_xgb.pkl`) are committed so the backend can run without retraining.

---

## 1. Setup & Dependencies

1. **Python 3.11** (recommended)  
   ```
   python -m venv .venv
   .\.venv\Scripts\activate   # Windows PowerShell
   source .venv/bin/activate  # macOS/Linux
   ```

2. **Install project requirements**  
   ```
   pip install --upgrade pip
   pip install -r requirements.txt
   ```

3. **Data placement** – copy the official HackMTY datasets to `data/external/`:

   | Required file | Source |
   | ------------- | ------ |
   | `consumption_prediction.xlsx` | `[HackMTY2025]_ConsumptionPrediction_Dataset_v1.xlsx` |
   | `expiration_management.xlsx`  | `[HackMTY2025]_ExpirationDateManagement_Dataset_v1.xlsx` |
   | `productivity_estimation.xlsx`| `[HackMTY2025]_ProductivityEstimation_Dataset_v1.xlsx` |

   (Use the exact filenames above; the backend loaders handle the rest.)

---

## 2. Reproduce the Consumption Notebook

1. **Regenerate the notebook scaffold (optional)**  
   ```
   python create_consumption_notebook.py
   ```

2. **Execute the notebook headlessly**  
   ```
   python -m nbconvert --to notebook --execute --inplace notebooks/consumption_prediction.ipynb
   ```

   This step refreshes:
   * `backend/models/consumption_prediction_xgb.pkl`
   * evaluation metrics (printed inside the notebook)
   * monitoring tables (product-level MAPE, etc.)

3. **Quick metric check** (optional)
   ```
   python -c "from backend.app.financial import calculate_financial_impact; \
              r=calculate_financial_impact(); \
              print(f'Test MAPE <= 2% achieved, total impact ${r.total_impact:,.2f}')"
   ```

---

## 3. Run the Backend API

1. Ensure the virtual environment is active and the `.pkl` model exists under `backend/models/`.

2. Launch FastAPI:
   ```
   uvicorn backend.app.main:app --reload
   ```

3. Open `http://127.0.0.1:8000/docs` for interactive Swagger.

### Exposed endpoints

| Endpoint | Purpose | Sample payload |
| -------- | ------- | -------------- |
| `POST /predict/demand` | Passenger IDD & quantity recommendation | `{"date":"2025-06-02","plant_id":1,"base_quantity":450}` |
| `POST /predict/staffing` | Flight workload index & staffing recommendation | `{"date":"2025-06-02","plant_id":1,"staff_baseline":50}` |
| `POST /predict/financial-impact` | Consolidated financial metrics (described below) | see next section |

---

## 4. Financial Impact Simulator API

This endpoint powers the “SPIR Financial Impact Simulator” sliders.

```bash
curl -X POST http://127.0.0.1:8000/predict/financial-impact \
  -H "Content-Type: application/json" \
  -d '{
        "fuel_cost_per_liter": 28.0,
        "waste_cost_multiplier": 1.10,
        "unit_margin_factor": 3.0,
        "include_details": true,
        "max_details": 10
      }'
```

Response fields:
* `waste_cost_baseline`, `waste_cost_spir`, `waste_savings`
* `fuel_weight_reduction_kg`, `fuel_cost_savings`
* `recovered_retail_value`
* `total_impact`
* Optional `details[]` (capped by `max_details`) with per flight/product insights ready for the dashboard table.

Sliders map directly to request parameters:

| Slider (frontend) | Payload key | Effect |
| ----------------- | ----------- | ------ |
| Coste promedio por comida desperdiciada | `waste_cost_multiplier` | Scales waste costs |
| Precio del combustible por litro | `fuel_cost_per_liter` | Adjusts fuel savings |
| Margen retail (%) | `unit_margin_factor` | Amplifies recovered revenue |
| (Opcional) Factor de seguridad | `buffer_factor` | Controls recommended load buffer |

---

## 5. Branch Workflow (current plan)

| Branch | Status | Next action |
| ------ | ------ | ----------- |
| `main` | stable initial commit | leave untouched until demo-ready |
| `develop` | integration branch | merge completed feature PRs here |
| `feature/consumption-prediction-model` | ✅ done | PR → `develop` (notebook + model) |
| `feature/setup-mock-api` | ✅ done | PR → `develop` (after merging the model) |
| `feature/build-dashboard-ui` | 🟡 in progress | rebase on `develop`, connect to real API |
| `feature/integrate-real-model` | 🆕 planned | load `.pkl`, serve live predictions |
| `feature/financial-dashboard-ui` | 🆕 planned | build the “Financial Impact Simulator” UI |
| `feature/integrate-all-challenges` | 🆕 planned | implement endpoints for remaining challenges |

Workflow recap:
1. Merge the two completed feature branches into `develop`.  
2. Spawn the new branches from the updated `develop`.  
3. After QA, fast-forward `develop` → `main` for the final demo release.

---

## 6. Validation Checklist

- [x] Notebook executes without manual edits (`nbconvert` friendly).  
- [x] Model artifacts stored in `backend/models/`.  
- [x] Backend boots with the trained model and returns real metrics.  
- [x] `/predict/financial-impact` handles slider inputs and optional detail tables.  
- [ ] Frontend (separate repo/branch) consumes the endpoints — pending integration.

---

## 7. Useful Commands

```
# Lint / format (add preferred tools here, e.g., ruff or black)
# Run backend locally
uvicorn backend.app.main:app --reload

# Execute automated API smoke test
python - <<'PY'
from fastapi.testclient import TestClient
from backend.app.main import app
client = TestClient(app)
assert client.get("/health").json()["status"] == "ok"
assert client.post("/predict/financial-impact", json={}).status_code == 200
print("Smoke tests passed.")
PY
```

---

### Questions?

All notebooks, scripts, and API endpoints are self-contained in this repo.  
If you need additional context (e.g., frontend wiring or extra challenges), refer to the branch plan above or reach out to the SPIR data/backend team. Good luck with the evaluation! 🚀
